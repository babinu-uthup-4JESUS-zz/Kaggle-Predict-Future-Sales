{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The idea here is to design a gradient boosting prediction algorithm using tensorflow. We will be using estimator API, which allows us seamless transition to other models !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory for storing metadata related to the model. This way, we can easily build models step by step, starting\n",
    "# from the previous checkpoint, in cases when we have large amount of data.\n",
    "OUTDIR = 'sample_model_metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The pandas input function which is to be fed to the estimator API. NOTE : Since the syntax is very similar, we could \n",
    "# have used one function for training and evaluation as well, but we have decided to keep them separately for the sake\n",
    "# of clarity.\n",
    "def make_train_input_fn(df, num_epochs=1, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        y=df['item_cnt_month'],\n",
    "        batch_size=128,\n",
    "        num_epochs=num_epochs,\n",
    "        shuffle=shuffle,\n",
    "        queue_capacity=2000)\n",
    "\n",
    "def make_eval_input_fn(df):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        y=df['item_cnt_month'],\n",
    "        batch_size=128,\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "        queue_capacity=2000)\n",
    "\n",
    "def make_prediction_input_fn(df):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        batch_size=128,\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "        queue_capacity=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_PREDICTOR_COLS = ['date_block_num', 'shop_id', 'item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This routine makes the input in a tensorflow digestible form.\n",
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in REL_PREDICTOR_COLS]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Get relevant data into pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train = pd.read_csv(\"input/sales_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data = sales_train[['date_block_num', 'shop_id', 'item_id', 'item_cnt_day' ]].groupby(\n",
    "    ['date_block_num', 'shop_id', 'item_id']).sum()\n",
    "monthly_sales_data.rename(columns={'item_cnt_day':'item_cnt_month'}, inplace=True)\n",
    "monthly_sales_data.reset_index(['date_block_num', 'shop_id', 'item_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_month'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What next ?\n",
    "\n",
    "One option for us would be to add relevant data from other files and see if we can extract something more from given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops = pd.read_csv('input/shops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['shop_name', 'shop_id'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shops.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categories = pd.read_csv('input/item_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_category_name', 'item_category_id'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_categories.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('input/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_name', 'item_id', 'item_category_id'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use item_category_id as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_to_item_category_id = dict(zip(items.item_id, items.item_category_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data['item_category_id'] = monthly_sales_data['item_id'].apply(lambda x : item_id_to_item_category_id.get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = monthly_sales_data[(monthly_sales_data.date_block_num != 32) &(monthly_sales_data.date_block_num != 33)]\n",
    "validation_data = monthly_sales_data[monthly_sales_data.date_block_num == 32]\n",
    "test_data = monthly_sales_data[monthly_sales_data.date_block_num == 33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Addtitional specific tensorflow functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train any model, for which a tensorflow estimator API is built. This way, we can test out several models with a one\n",
    "# line change.\n",
    "def get_trained_model(model, train_data, outdir=OUTDIR, logging_mode=tf.logging.INFO):\n",
    "    \n",
    "    tf.logging.set_verbosity(logging_mode)\n",
    "    \n",
    "    # Delete the directory corresponding to metadata of model so as to build it from scratch.\n",
    "    shutil.rmtree(outdir, ignore_errors=True)\n",
    "\n",
    "    # Train data for a reasonable number of epochs (100) as default.\n",
    "    model.train(make_train_input_fn(train_data, num_epochs=100, shuffle=False))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_from_model(model, test_data):\n",
    "    predictions = model.predict(input_fn=make_prediction_input_fn(test_data)) \n",
    "    return [x['predictions'][0] for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the model and obtain validation score. Also, make score that the predictions are clipped so that they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'sample_model_metadata', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1426ca320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/data_flow_ops.py:1236: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 0 into sample_model_metadata/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 13.0625, step = 0\n",
      "INFO:tensorflow:loss = 2.7483807, step = 99 (1.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.4248\n",
      "INFO:tensorflow:loss = 17.070436, step = 199 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.665\n",
      "INFO:tensorflow:loss = 18.393755, step = 299 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.686\n",
      "INFO:tensorflow:loss = 2.1596873, step = 399 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.691\n",
      "INFO:tensorflow:loss = 10.851213, step = 499 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.522\n",
      "INFO:tensorflow:loss = 55.0658, step = 599 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.729\n",
      "INFO:tensorflow:loss = 28.832756, step = 699 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.368\n",
      "INFO:tensorflow:loss = 5.6023912, step = 799 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.742\n",
      "INFO:tensorflow:loss = 86.23106, step = 899 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.902\n",
      "INFO:tensorflow:loss = 6.695802, step = 999 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.294\n",
      "INFO:tensorflow:loss = 10.863902, step = 1099 (0.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.95\n",
      "INFO:tensorflow:loss = 58.53209, step = 1199 (0.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.503\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into sample_model_metadata/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Loss for final step: 1.5260549.\n"
     ]
    }
   ],
   "source": [
    "model = get_trained_model(tf.estimator.BoostedTreesRegressor(feature_columns=make_feature_cols(),\n",
    "                                                             n_batches_per_layer=2,\n",
    "                                                             model_dir=OUTDIR),\n",
    "                         train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /Users/babs4JESUS/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from sample_model_metadata/model.ckpt-1200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "model_predictions = get_predictions_from_model(model, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(model_predictions, validation_data):\n",
    "    actual_vals = np.clip(validation_data.item_cnt_month.values, 0, 20)\n",
    "    return np.sqrt(mean_squared_error(actual_vals, np.clip(model_predictions, 0, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6254074716990776"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(model_predictions, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us check out by adding item_category_id also here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_PREDICTOR_COLS = ['date_block_num', 'shop_id', 'item_id', 'item_category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'sample_model_metadata', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x14466a4a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 0 into sample_model_metadata/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 13.0625, step = 0\n",
      "INFO:tensorflow:loss = 1.9086015, step = 98 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.2053\n",
      "INFO:tensorflow:loss = 16.995735, step = 198 (0.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.314\n",
      "INFO:tensorflow:loss = 18.500124, step = 298 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.528\n",
      "INFO:tensorflow:loss = 2.2622955, step = 398 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.815\n",
      "INFO:tensorflow:loss = 9.546875, step = 498 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.181\n",
      "INFO:tensorflow:loss = 45.112022, step = 598 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.122\n",
      "INFO:tensorflow:loss = 26.890656, step = 698 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.96\n",
      "INFO:tensorflow:loss = 8.055868, step = 798 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.961\n",
      "INFO:tensorflow:loss = 71.23546, step = 898 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.981\n",
      "INFO:tensorflow:loss = 5.504945, step = 998 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.158\n",
      "INFO:tensorflow:loss = 6.211841, step = 1098 (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.645\n",
      "INFO:tensorflow:loss = 52.839867, step = 1198 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.424\n",
      "INFO:tensorflow:loss = 167.59494, step = 1298 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.082\n",
      "INFO:tensorflow:loss = 12.552379, step = 1398 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.882\n",
      "INFO:tensorflow:loss = 29.922369, step = 1498 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.308\n",
      "INFO:tensorflow:loss = 9.020266, step = 1598 (0.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.947\n",
      "INFO:tensorflow:loss = 3.2880077, step = 1698 (0.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.203\n",
      "INFO:tensorflow:loss = 1.9481611, step = 1798 (0.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.299\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into sample_model_metadata/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Loss for final step: 1.38729.\n"
     ]
    }
   ],
   "source": [
    "model = get_trained_model(tf.estimator.BoostedTreesRegressor(feature_columns=make_feature_cols(),\n",
    "                                                             n_batches_per_layer=3,\n",
    "                                                             model_dir=OUTDIR),\n",
    "                         train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from sample_model_metadata/model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "model_predictions = get_predictions_from_model(model, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.611500363632769"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(model_predictions, validation_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
