{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The idea here is to design a gradient boosting prediction algorithm using tensorflow. We will be using estimator API, which allows us seamless transition to other models !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory for storing metadata related to the model. This way, we can easily build models step by step, starting\n",
    "# from the previous checkpoint, in cases when we have large amount of data.\n",
    "OUTDIR = 'sample_model_metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The pandas input function which is to be fed to the estimator API. NOTE : Since the syntax is very similar, we could \n",
    "# have used one function for training and evaluation as well, but we have decided to keep them separately for the sake\n",
    "# of clarity.\n",
    "def make_train_input_fn(df, num_epochs=1, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        y=df['item_cnt_month'],\n",
    "        batch_size=128,\n",
    "        num_epochs=num_epochs,\n",
    "        shuffle=shuffle,\n",
    "        queue_capacity=2000)\n",
    "\n",
    "def make_eval_input_fn(df):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        y=df['item_cnt_month'],\n",
    "        batch_size=128,\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "        queue_capacity=2000)\n",
    "\n",
    "def make_prediction_input_fn(df):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        batch_size=128,\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "        queue_capacity=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_PREDICTOR_COLS = ['date_block_num', 'shop_id', 'item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This routine makes the input in a tensorflow digestible form.\n",
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in REL_PREDICTOR_COLS]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Get relevant data into pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train = pd.read_csv(\"input/sales_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data = sales_train[['date_block_num', 'shop_id', 'item_id', 'item_cnt_day' ]].groupby(\n",
    "    ['date_block_num', 'shop_id', 'item_id']).sum()\n",
    "monthly_sales_data.rename(columns={'item_cnt_day':'item_cnt_month'}, inplace=True)\n",
    "monthly_sales_data.reset_index(['date_block_num', 'shop_id', 'item_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_month'], dtype='object')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = monthly_sales_data[monthly_sales_data.date_block_num != 32]\n",
    "validation_data = monthly_sales_data[monthly_sales_data.date_block_num == 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Addtitional specific tensorflow functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train any model, for which a tensorflow estimator API is built. This way, we can test out several models with a one\n",
    "# line change.\n",
    "def get_trained_model(model, train_data, outdir=OUTDIR, logging_mode=tf.logging.INFO):\n",
    "    \n",
    "    tf.logging.set_verbosity(logging_mode)\n",
    "    \n",
    "    # Delete the directory corresponding to metadata of model so as to build it from scratch.\n",
    "    shutil.rmtree(outdir, ignore_errors=True)\n",
    "\n",
    "    # Train data for a reasonable number of epochs (100) as default.\n",
    "    model.train(make_train_input_fn(train_data, num_epochs=100, shuffle=False))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_from_model(model, test_data):\n",
    "    predictions = model.predict(input_fn=make_prediction_input_fn(test_data)) \n",
    "    return [x['predictions'][0] for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the model and obtain validation score. Also, make score that the predictions are clipped so that they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'sample_model_metadata', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1403ab080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 0 into sample_model_metadata/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 13.0625, step = 0\n",
      "INFO:tensorflow:loss = 2.0483794, step = 99 (1.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.1644\n",
      "INFO:tensorflow:loss = 16.902618, step = 199 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.344\n",
      "INFO:tensorflow:loss = 18.208158, step = 299 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.174\n",
      "INFO:tensorflow:loss = 2.134518, step = 399 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.495\n",
      "INFO:tensorflow:loss = 9.3928585, step = 499 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.729\n",
      "INFO:tensorflow:loss = 52.009342, step = 599 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.444\n",
      "INFO:tensorflow:loss = 27.523643, step = 699 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.256\n",
      "INFO:tensorflow:loss = 4.755157, step = 799 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.063\n",
      "INFO:tensorflow:loss = 77.02898, step = 899 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.089\n",
      "INFO:tensorflow:loss = 6.0912166, step = 999 (0.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.767\n",
      "INFO:tensorflow:loss = 10.470612, step = 1099 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.099\n",
      "INFO:tensorflow:loss = 52.873344, step = 1199 (0.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.472\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into sample_model_metadata/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Loss for final step: 1.5799843.\n"
     ]
    }
   ],
   "source": [
    "model = get_trained_model(tf.estimator.BoostedTreesRegressor(feature_columns=make_feature_cols(),\n",
    "                                                             n_batches_per_layer=2,\n",
    "                                                             model_dir=OUTDIR),\n",
    "                         train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from sample_model_metadata/model.ckpt-1200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "model_predictions = get_predictions_from_model(model, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(model_predictions, validation_data):\n",
    "    actual_vals = np.clip(validation_data.item_cnt_month.values, 0, 20)\n",
    "    return np.sqrt(mean_squared_error(actual_vals, np.clip(model_predictions, 0, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6254074716990776"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(model_predictions, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What next ?\n",
    "\n",
    "One option for us would be to add relevant data from other files and see if we can extract something more from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops = pd.read_csv('input/shops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['shop_name', 'shop_id'], dtype='object')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shops.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categories = pd.read_csv('input/item_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_category_name', 'item_category_id'], dtype='object')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_categories.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('input/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_name', 'item_id', 'item_category_id'], dtype='object')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use item_category_id as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_to_item_category_id = dict(zip(items.item_id, items.item_category_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data['item_category_id'] = monthly_sales_data['item_id'].apply(lambda x : item_id_to_item_category_id.get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = monthly_sales_data[monthly_sales_data.date_block_num != 32]\n",
    "validation_data = monthly_sales_data[monthly_sales_data.date_block_num == 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_PREDICTOR_COLS = ['date_block_num', 'shop_id', 'item_id', 'item_category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'sample_model_metadata', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1450add68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 0 into sample_model_metadata/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 13.0625, step = 0\n",
      "INFO:tensorflow:loss = 1.9086015, step = 98 (1.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.9911\n",
      "INFO:tensorflow:loss = 16.995735, step = 198 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.351\n",
      "INFO:tensorflow:loss = 18.500124, step = 298 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.734\n",
      "INFO:tensorflow:loss = 2.2622955, step = 398 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.297\n",
      "INFO:tensorflow:loss = 9.546875, step = 498 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.659\n",
      "INFO:tensorflow:loss = 45.112022, step = 598 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.524\n",
      "INFO:tensorflow:loss = 26.890656, step = 698 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.53\n",
      "INFO:tensorflow:loss = 8.055868, step = 798 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.216\n",
      "INFO:tensorflow:loss = 71.23546, step = 898 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.518\n",
      "INFO:tensorflow:loss = 5.504945, step = 998 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.421\n",
      "INFO:tensorflow:loss = 6.211841, step = 1098 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.239\n",
      "INFO:tensorflow:loss = 52.839867, step = 1198 (0.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.364\n",
      "INFO:tensorflow:loss = 167.59494, step = 1298 (0.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.205\n",
      "INFO:tensorflow:loss = 12.552379, step = 1398 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.643\n",
      "INFO:tensorflow:loss = 29.922369, step = 1498 (0.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.099\n",
      "INFO:tensorflow:loss = 9.020266, step = 1598 (0.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.363\n",
      "INFO:tensorflow:loss = 3.2880077, step = 1698 (0.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.141\n",
      "INFO:tensorflow:loss = 1.9481611, step = 1798 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.268\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into sample_model_metadata/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Loss for final step: 1.38729.\n"
     ]
    }
   ],
   "source": [
    "model = get_trained_model(tf.estimator.BoostedTreesRegressor(feature_columns=make_feature_cols(),\n",
    "                                                             n_batches_per_layer=3,\n",
    "                                                             model_dir=OUTDIR),\n",
    "                         train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from sample_model_metadata/model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "model_predictions = get_predictions_from_model(model, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.611500363632769"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(model_predictions, validation_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
